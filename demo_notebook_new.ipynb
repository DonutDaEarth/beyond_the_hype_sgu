{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad73f230",
   "metadata": {},
   "source": [
    "# Beyond the Hype: When GPT-2 Hallucinates\n",
    "\n",
    "## Demonstrating Factual Inaccuracies in AI-Generated Content\n",
    "\n",
    "**Project Thesis:** Despite GPT-2's impressive text generation capabilities, the model frequently generates plausible-sounding but factually incorrect or nonsensical information (hallucinations), making it unreliable for tasks requiring factual accuracy like summarization, translation, and information retrieval.\n",
    "\n",
    "**Key Limitation:** Factual Inaccuracy (Hallucination)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2416a",
   "metadata": {},
   "source": [
    "## Setup: Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb37d080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run once)\n",
    "%pip install transformers torch pandas matplotlib seaborn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2cd656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úì Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6779cd1d",
   "metadata": {},
   "source": [
    "## Load GPT-2 Model\n",
    "\n",
    "We'll use **GPT-2** (OpenAI, 2019) - a 117M parameter autoregressive language model.\n",
    "\n",
    "**Why GPT-2?**\n",
    "- Widely used for text generation tasks\n",
    "- Known for producing fluent, coherent text\n",
    "- **Critical flaw:** Frequently generates plausible-sounding but factually incorrect information (hallucinations)\n",
    "\n",
    "**The Problem:** When GPT-2 generates text, it's predicting the most likely next word based on patterns in training data, NOT checking facts or maintaining consistency with reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a95cec21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GPT-2 model...\n",
      "\n",
      "============================================================\n",
      "‚úì GPT-2 Model Loaded Successfully!\n",
      "============================================================\n",
      "\n",
      "üìä Model Details:\n",
      "  ‚Ä¢ Model: GPT-2\n",
      "  ‚Ä¢ Parameters: 117 million\n",
      "  ‚Ä¢ Developer: OpenAI (2019)\n",
      "  ‚Ä¢ Architecture: Transformer decoder-only\n",
      "============================================================\n",
      "============================================================\n",
      "‚úì GPT-2 Model Loaded Successfully!\n",
      "============================================================\n",
      "\n",
      "üìä Model Details:\n",
      "  ‚Ä¢ Model: GPT-2\n",
      "  ‚Ä¢ Parameters: 117 million\n",
      "  ‚Ä¢ Developer: OpenAI (2019)\n",
      "  ‚Ä¢ Architecture: Transformer decoder-only\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading GPT-2 model...\\n\")\n",
    "\n",
    "# Load GPT-2\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
    "gpt2_model.eval()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"‚úì GPT-2 Model Loaded Successfully!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìä Model Details:\")\n",
    "print(f\"  ‚Ä¢ Model: GPT-2\")\n",
    "print(f\"  ‚Ä¢ Parameters: 117 million\")\n",
    "print(f\"  ‚Ä¢ Developer: OpenAI (2019)\")\n",
    "print(f\"  ‚Ä¢ Architecture: Transformer decoder-only\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d918148",
   "metadata": {},
   "source": [
    "## Helper Functions for Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65959a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Helper functions defined!\n"
     ]
    }
   ],
   "source": [
    "def generate_gpt2_text(prompt, max_length=200, temperature=0.8, num_return=1):\n",
    "    \"\"\"Generate text using GPT-2 model\"\"\"\n",
    "    input_ids = gpt2_tokenizer.encode(prompt, return_tensors='pt')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = gpt2_model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=num_return,\n",
    "            pad_token_id=gpt2_tokenizer.eos_token_id,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95\n",
    "        )\n",
    "    \n",
    "    return gpt2_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def display_hallucination_comparison(test_name, prompt, ground_truth, gpt2_output, hallucinations):\n",
    "    \"\"\"Display a formatted comparison highlighting hallucinations\"\"\"\n",
    "    html = f\"\"\"\n",
    "    <div style='background-color: #f0f0f0; padding: 20px; border-radius: 10px; margin: 10px 0; border: 2px solid #95a5a6;'>\n",
    "        <h3 style='color: #2c3e50;'>üß™ Test Case: {test_name}</h3>\n",
    "        <div style='background-color: white; color: #2c3e50; padding: 15px; margin: 10px 0; border-left: 4px solid #3498db;'>\n",
    "            <strong style='font-size: 16px;'>üìù Prompt:</strong><br>\n",
    "            <span style='font-size: 16px; color: #2c3e50;'>{prompt}</span>\n",
    "        </div>\n",
    "        <div style='background-color: #d4edda; color: #155724; padding: 15px; margin: 10px 0; border-left: 4px solid #28a745;'>\n",
    "            <strong style='font-size: 16px;'>‚úì Ground Truth (Actual Facts):</strong><br>\n",
    "            <span style='font-size: 16px; color: #155724;'>{ground_truth}</span>\n",
    "        </div>\n",
    "        <div style='background-color: #f8d7da; color: #721c24; padding: 15px; margin: 10px 0; border-left: 4px solid #dc3545; border: 2px solid #dc3545;'>\n",
    "            <strong style='font-size: 16px;'>‚ùå GPT-2 Output (Contains Hallucinations):</strong><br>\n",
    "            <span style='font-size: 16px; color: #721c24;'>{gpt2_output}</span>\n",
    "        </div>\n",
    "        <div style='background-color: #fff3cd; color: #856404; padding: 15px; margin: 10px 0; border-left: 4px solid #ffc107;'>\n",
    "            <strong style='font-size: 16px;'>üö® Identified Hallucinations:</strong><br>\n",
    "            <ul style='margin: 10px 0; font-size: 15px;'>\n",
    "    \"\"\"\n",
    "    \n",
    "    for hallucination in hallucinations:\n",
    "        html += f\"<li style='margin: 5px 0; color: #856404;'><strong>{hallucination}</strong></li>\"\n",
    "    \n",
    "    html += \"\"\"\n",
    "            </ul>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(html))\n",
    "\n",
    "print(\"‚úì Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa3de44",
   "metadata": {},
   "source": [
    "---\n",
    "# üéØ DEMONSTRATION 1: Historical Facts Hallucination\n",
    "\n",
    "**Task:** Generate text about historical events\n",
    "\n",
    "**Risk:** The model will confidently state incorrect dates, names, and events that sound plausible but are completely fabricated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7db5d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background-color: #f0f0f0; padding: 20px; border-radius: 10px; margin: 10px 0; border: 2px solid #95a5a6;'>\n",
       "        <h3 style='color: #2c3e50;'>üß™ Test Case: Historical Event - WWII End Date</h3>\n",
       "        <div style='background-color: white; color: #2c3e50; padding: 15px; margin: 10px 0; border-left: 4px solid #3498db;'>\n",
       "            <strong style='font-size: 16px;'>üìù Prompt:</strong><br>\n",
       "            <span style='font-size: 16px; color: #2c3e50;'>World War II ended in</span>\n",
       "        </div>\n",
       "        <div style='background-color: #d4edda; color: #155724; padding: 15px; margin: 10px 0; border-left: 4px solid #28a745;'>\n",
       "            <strong style='font-size: 16px;'>‚úì Ground Truth (Actual Facts):</strong><br>\n",
       "            <span style='font-size: 16px; color: #155724;'>World War II ended in 1945 (May 8, 1945 in Europe, September 2, 1945 in the Pacific)</span>\n",
       "        </div>\n",
       "        <div style='background-color: #f8d7da; color: #721c24; padding: 15px; margin: 10px 0; border-left: 4px solid #dc3545; border: 2px solid #dc3545;'>\n",
       "            <strong style='font-size: 16px;'>‚ùå GPT-2 Output (Contains Hallucinations):</strong><br>\n",
       "            <span style='font-size: 16px; color: #721c24;'>World War II ended in a stalemate, with the U.S. able to defeat the Soviet Union in its own backyard and the Allies able to achieve victory in the war in Europe.\n",
       "\n",
       "\"I'm sure many of you are thinking: What happened to the Allies? What happened to the Allies? What happened to the Allies? It seems that we were not able to see the end of the war in Europe, because the British did not want to go down like the Germans did. The</span>\n",
       "        </div>\n",
       "        <div style='background-color: #fff3cd; color: #856404; padding: 15px; margin: 10px 0; border-left: 4px solid #ffc107;'>\n",
       "            <strong style='font-size: 16px;'>üö® Identified Hallucinations:</strong><br>\n",
       "            <ul style='margin: 10px 0; font-size: 15px;'>\n",
       "    <li style='margin: 5px 0; color: #856404;'><strong>Check if GPT-2 states a different year</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for invented battles or events</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for incorrect surrender details</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for fabricated historical figures</strong></li>\n",
       "            </ul>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "### üîç Analysis\n",
       "GPT-2 generates text based on statistical patterns, not factual knowledge. Even for well-documented historical events, it may:\n",
       "- Generate plausible-sounding but incorrect dates\n",
       "- Invent non-existent historical details\n",
       "- Confuse different events or time periods\n",
       "- Mix facts from different contexts\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 1: World War II End Date\n",
    "prompt1 = \"World War II ended in\"\n",
    "\n",
    "gpt2_output1 = generate_gpt2_text(prompt1, max_length=100, temperature=0.7)\n",
    "\n",
    "ground_truth1 = \"World War II ended in 1945 (May 8, 1945 in Europe, September 2, 1945 in the Pacific)\"\n",
    "\n",
    "hallucinations1 = [\n",
    "    \"Check if GPT-2 states a different year\",\n",
    "    \"Check for invented battles or events\",\n",
    "    \"Check for incorrect surrender details\",\n",
    "    \"Check for fabricated historical figures\"\n",
    "]\n",
    "\n",
    "display_hallucination_comparison(\n",
    "    \"Historical Event - WWII End Date\",\n",
    "    prompt1,\n",
    "    ground_truth1,\n",
    "    gpt2_output1,\n",
    "    hallucinations1\n",
    ")\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "### üîç Analysis\n",
    "GPT-2 generates text based on statistical patterns, not factual knowledge. Even for well-documented historical events, it may:\n",
    "- Generate plausible-sounding but incorrect dates\n",
    "- Invent non-existent historical details\n",
    "- Confuse different events or time periods\n",
    "- Mix facts from different contexts\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6bce6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background-color: #f0f0f0; padding: 20px; border-radius: 10px; margin: 10px 0; border: 2px solid #95a5a6;'>\n",
       "        <h3 style='color: #2c3e50;'>üß™ Test Case: Scientific Discovery - Theory of Relativity</h3>\n",
       "        <div style='background-color: white; color: #2c3e50; padding: 15px; margin: 10px 0; border-left: 4px solid #3498db;'>\n",
       "            <strong style='font-size: 16px;'>üìù Prompt:</strong><br>\n",
       "            <span style='font-size: 16px; color: #2c3e50;'>Albert Einstein discovered the theory of relativity in</span>\n",
       "        </div>\n",
       "        <div style='background-color: #d4edda; color: #155724; padding: 15px; margin: 10px 0; border-left: 4px solid #28a745;'>\n",
       "            <strong style='font-size: 16px;'>‚úì Ground Truth (Actual Facts):</strong><br>\n",
       "            <span style='font-size: 16px; color: #155724;'>Albert Einstein published the special theory of relativity in 1905 and the general theory of relativity in 1915</span>\n",
       "        </div>\n",
       "        <div style='background-color: #f8d7da; color: #721c24; padding: 15px; margin: 10px 0; border-left: 4px solid #dc3545; border: 2px solid #dc3545;'>\n",
       "            <strong style='font-size: 16px;'>‚ùå GPT-2 Output (Contains Hallucinations):</strong><br>\n",
       "            <span style='font-size: 16px; color: #721c24;'>Albert Einstein discovered the theory of relativity in 1872, and Einstein believed it was a true fact of physics that the universe is expanding.\n",
       "\n",
       "Einstein wrote the famous \"Einstein's Second Law of Thermodynamics\", which states that when the law of motion is used to describe something, it must be true.\n",
       "\n",
       "But there's another way Einstein could have known about the law of motion. He could have been wrong about the number of photons in a photon.\n",
       "\n",
       "In fact, as we've seen, Einstein knew that the number of photons in a photon is a good measure of</span>\n",
       "        </div>\n",
       "        <div style='background-color: #fff3cd; color: #856404; padding: 15px; margin: 10px 0; border-left: 4px solid #ffc107;'>\n",
       "            <strong style='font-size: 16px;'>üö® Identified Hallucinations:</strong><br>\n",
       "            <ul style='margin: 10px 0; font-size: 15px;'>\n",
       "    <li style='margin: 5px 0; color: #856404;'><strong>Check for incorrect year</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for invented collaborators or universities</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for fabricated discovery details</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for incorrect scientific claims</strong></li>\n",
       "            </ul>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 2: Scientific Discovery\n",
    "prompt2 = \"Albert Einstein discovered the theory of relativity in\"\n",
    "\n",
    "gpt2_output2 = generate_gpt2_text(prompt2, max_length=120, temperature=0.7)\n",
    "\n",
    "ground_truth2 = \"Albert Einstein published the special theory of relativity in 1905 and the general theory of relativity in 1915\"\n",
    "\n",
    "hallucinations2 = [\n",
    "    \"Check for incorrect year\",\n",
    "    \"Check for invented collaborators or universities\",\n",
    "    \"Check for fabricated discovery details\",\n",
    "    \"Check for incorrect scientific claims\"\n",
    "]\n",
    "\n",
    "display_hallucination_comparison(\n",
    "    \"Scientific Discovery - Theory of Relativity\",\n",
    "    prompt2,\n",
    "    ground_truth2,\n",
    "    gpt2_output2,\n",
    "    hallucinations2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8cb40d",
   "metadata": {},
   "source": [
    "---\n",
    "# üéØ DEMONSTRATION 2: Geographic Information Hallucination\n",
    "\n",
    "**Task:** Complete sentences about geography\n",
    "\n",
    "**Risk:** GPT-2 will fabricate capitals, populations, locations, and geographic features that don't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33c65da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background-color: #f0f0f0; padding: 20px; border-radius: 10px; margin: 10px 0; border: 2px solid #95a5a6;'>\n",
       "        <h3 style='color: #2c3e50;'>üß™ Test Case: Geographic Fact - Australian Capital</h3>\n",
       "        <div style='background-color: white; color: #2c3e50; padding: 15px; margin: 10px 0; border-left: 4px solid #3498db;'>\n",
       "            <strong style='font-size: 16px;'>üìù Prompt:</strong><br>\n",
       "            <span style='font-size: 16px; color: #2c3e50;'>The capital of Australia is</span>\n",
       "        </div>\n",
       "        <div style='background-color: #d4edda; color: #155724; padding: 15px; margin: 10px 0; border-left: 4px solid #28a745;'>\n",
       "            <strong style='font-size: 16px;'>‚úì Ground Truth (Actual Facts):</strong><br>\n",
       "            <span style='font-size: 16px; color: #155724;'>The capital of Australia is Canberra (not Sydney or Melbourne)</span>\n",
       "        </div>\n",
       "        <div style='background-color: #f8d7da; color: #721c24; padding: 15px; margin: 10px 0; border-left: 4px solid #dc3545; border: 2px solid #dc3545;'>\n",
       "            <strong style='font-size: 16px;'>‚ùå GPT-2 Output (Contains Hallucinations):</strong><br>\n",
       "            <span style='font-size: 16px; color: #721c24;'>The capital of Australia is in the heart of the West Australian landscape. It has been there since the late 18th century and is the centre of the Australian capital's cultural life. It has been the centre of the nation's cultural life for over a century.\n",
       "\n",
       "The capital has been the centre of Australia's cultural life for over a century.\n",
       "\n",
       "It has been the centre of the nation</span>\n",
       "        </div>\n",
       "        <div style='background-color: #fff3cd; color: #856404; padding: 15px; margin: 10px 0; border-left: 4px solid #ffc107;'>\n",
       "            <strong style='font-size: 16px;'>üö® Identified Hallucinations:</strong><br>\n",
       "            <ul style='margin: 10px 0; font-size: 15px;'>\n",
       "    <li style='margin: 5px 0; color: #856404;'><strong>Check if it states Sydney or Melbourne (common misconception)</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for invented city names</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for incorrect population figures</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for fabricated historical details</strong></li>\n",
       "            </ul>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 3: Country Capital\n",
    "prompt3 = \"The capital of Australia is\"\n",
    "\n",
    "gpt2_output3 = generate_gpt2_text(prompt3, max_length=80, temperature=0.7)\n",
    "\n",
    "ground_truth3 = \"The capital of Australia is Canberra (not Sydney or Melbourne)\"\n",
    "\n",
    "hallucinations3 = [\n",
    "    \"Check if it states Sydney or Melbourne (common misconception)\",\n",
    "    \"Check for invented city names\",\n",
    "    \"Check for incorrect population figures\",\n",
    "    \"Check for fabricated historical details\"\n",
    "]\n",
    "\n",
    "display_hallucination_comparison(\n",
    "    \"Geographic Fact - Australian Capital\",\n",
    "    prompt3,\n",
    "    ground_truth3,\n",
    "    gpt2_output3,\n",
    "    hallucinations3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "348b4f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background-color: #f0f0f0; padding: 20px; border-radius: 10px; margin: 10px 0; border: 2px solid #95a5a6;'>\n",
       "        <h3 style='color: #2c3e50;'>üß™ Test Case: Geographic Fact - Mount Everest</h3>\n",
       "        <div style='background-color: white; color: #2c3e50; padding: 15px; margin: 10px 0; border-left: 4px solid #3498db;'>\n",
       "            <strong style='font-size: 16px;'>üìù Prompt:</strong><br>\n",
       "            <span style='font-size: 16px; color: #2c3e50;'>Mount Everest is located in</span>\n",
       "        </div>\n",
       "        <div style='background-color: #d4edda; color: #155724; padding: 15px; margin: 10px 0; border-left: 4px solid #28a745;'>\n",
       "            <strong style='font-size: 16px;'>‚úì Ground Truth (Actual Facts):</strong><br>\n",
       "            <span style='font-size: 16px; color: #155724;'>Mount Everest is located on the border between Nepal and Tibet (China), with a height of 8,848.86 meters</span>\n",
       "        </div>\n",
       "        <div style='background-color: #f8d7da; color: #721c24; padding: 15px; margin: 10px 0; border-left: 4px solid #dc3545; border: 2px solid #dc3545;'>\n",
       "            <strong style='font-size: 16px;'>‚ùå GPT-2 Output (Contains Hallucinations):</strong><br>\n",
       "            <span style='font-size: 16px; color: #721c24;'>Mount Everest is located in the Kota Chai Mountains in the Indian Ocean, about 300 kilometers (300 miles) northeast of the city of Kathmandu. It is an ancient, highly protected mountain range, and the area is home to a variety of species of mountain animals. It is also home to the largest mountain range in Nepal, the Himalayas, and is known as the \"Himalayan mountain range.\" The Himalayan mountain range is dominated by the Himalayan Himalayan, which</span>\n",
       "        </div>\n",
       "        <div style='background-color: #fff3cd; color: #856404; padding: 15px; margin: 10px 0; border-left: 4px solid #ffc107;'>\n",
       "            <strong style='font-size: 16px;'>üö® Identified Hallucinations:</strong><br>\n",
       "            <ul style='margin: 10px 0; font-size: 15px;'>\n",
       "    <li style='margin: 5px 0; color: #856404;'><strong>Check for incorrect location</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for fabricated height measurements</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for invented surrounding mountains</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for false climbing records</strong></li>\n",
       "            </ul>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "### üí° Key Insight #1\n",
       "GPT-2 generates text that **sounds plausible** but lacks grounding in factual knowledge. The model:\n",
       "- Doesn't \"know\" facts - it predicts likely word sequences\n",
       "- Can't distinguish between true and false information\n",
       "- Confidently generates incorrect information\n",
       "- Produces fluent but factually wrong text\n",
       "\n",
       "**This makes it unreliable for any factual information tasks!**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 4: Mountain Location\n",
    "prompt4 = \"Mount Everest is located in\"\n",
    "\n",
    "gpt2_output4 = generate_gpt2_text(prompt4, max_length=100, temperature=0.7)\n",
    "\n",
    "ground_truth4 = \"Mount Everest is located on the border between Nepal and Tibet (China), with a height of 8,848.86 meters\"\n",
    "\n",
    "hallucinations4 = [\n",
    "    \"Check for incorrect location\",\n",
    "    \"Check for fabricated height measurements\",\n",
    "    \"Check for invented surrounding mountains\",\n",
    "    \"Check for false climbing records\"\n",
    "]\n",
    "\n",
    "display_hallucination_comparison(\n",
    "    \"Geographic Fact - Mount Everest\",\n",
    "    prompt4,\n",
    "    ground_truth4,\n",
    "    gpt2_output4,\n",
    "    hallucinations4\n",
    ")\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "### üí° Key Insight #1\n",
    "GPT-2 generates text that **sounds plausible** but lacks grounding in factual knowledge. The model:\n",
    "- Doesn't \"know\" facts - it predicts likely word sequences\n",
    "- Can't distinguish between true and false information\n",
    "- Confidently generates incorrect information\n",
    "- Produces fluent but factually wrong text\n",
    "\n",
    "**This makes it unreliable for any factual information tasks!**\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8710a4f",
   "metadata": {},
   "source": [
    "---\n",
    "# üéØ DEMONSTRATION 3: News Summarization Hallucination\n",
    "\n",
    "**Task:** Summarize news articles\n",
    "\n",
    "**Risk:** GPT-2 will add details that weren't in the original text, change key facts, or invent quotes and statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dfe6eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background-color: #f0f0f0; padding: 20px; border-radius: 10px; margin: 10px 0; border: 2px solid #95a5a6;'>\n",
       "        <h3 style='color: #2c3e50;'>üß™ Test Case: News Summarization - Battery Technology</h3>\n",
       "        <div style='background-color: white; color: #2c3e50; padding: 15px; margin: 10px 0; border-left: 4px solid #3498db;'>\n",
       "            <strong style='font-size: 16px;'>üìù Prompt:</strong><br>\n",
       "            <span style='font-size: 16px; color: #2c3e50;'>Summarize the news article</span>\n",
       "        </div>\n",
       "        <div style='background-color: #d4edda; color: #155724; padding: 15px; margin: 10px 0; border-left: 4px solid #28a745;'>\n",
       "            <strong style='font-size: 16px;'>‚úì Ground Truth (Actual Facts):</strong><br>\n",
       "            <span style='font-size: 16px; color: #155724;'>MIT scientists developed battery tech for 50% more EV range, tested over 1,000 cycles, available by 2026</span>\n",
       "        </div>\n",
       "        <div style='background-color: #f8d7da; color: #721c24; padding: 15px; margin: 10px 0; border-left: 4px solid #dc3545; border: 2px solid #dc3545;'>\n",
       "            <strong style='font-size: 16px;'>‚ùå GPT-2 Output (Contains Hallucinations):</strong><br>\n",
       "            <span style='font-size: 16px; color: #721c24;'>A breakthrough study published in Nature revealed that scientists at MIT \n",
       "have developed a new battery technology that could extend electric vehicle range by 50%. \n",
       "The research team, led by Dr. Sarah Chen, tested the batteries over 1,000 charge cycles. \n",
       "The technology is expected to be commercially available by 2026.\n",
       "\n",
       "TL;DR: We've created a new battery technology that could extend electric vehicle range by 50%\n",
       "\n",
       "The new battery technology was developed by the team at MIT \n",
       "\n",
       "According to the company, which also works as a research lab for the National Institute of Standards and Technology (NIST) in Cambridge, Massachusetts, the new technology could allow Tesla to reach up to 1,500 miles of range in the first year. \n",
       "\n",
       "\"Tesla's battery technology is a great leap forward in technology development, and it's a big step forward in our understanding of how electric vehicles work and how they function,\" said Dr. Chen.\n",
       "\n",
       "\"We are now able to fully extend the range of an electric vehicle by 30 percent. That's an amazing achievement, and we hope that we can make it possible for people to become fully self-driving vehicles,\" said Dr. Chen.\n",
       "\n",
       "The new technology</span>\n",
       "        </div>\n",
       "        <div style='background-color: #fff3cd; color: #856404; padding: 15px; margin: 10px 0; border-left: 4px solid #ffc107;'>\n",
       "            <strong style='font-size: 16px;'>üö® Identified Hallucinations:</strong><br>\n",
       "            <ul style='margin: 10px 0; font-size: 15px;'>\n",
       "    <li style='margin: 5px 0; color: #856404;'><strong>Check for changed percentages or numbers</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for invented researcher names or institutions</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for fabricated quotes or statements</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for added details not in original text</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for changed dates or timelines</strong></li>\n",
       "            </ul>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 5: News Article Summarization\n",
    "news_article = \"\"\"A breakthrough study published in Nature revealed that scientists at MIT \n",
    "have developed a new battery technology that could extend electric vehicle range by 50%. \n",
    "The research team, led by Dr. Sarah Chen, tested the batteries over 1,000 charge cycles. \n",
    "The technology is expected to be commercially available by 2026.\"\"\"\n",
    "\n",
    "prompt5 = news_article + \"\\n\\nTL;DR:\"\n",
    "\n",
    "gpt2_output5 = generate_gpt2_text(prompt5, max_length=250, temperature=0.7)\n",
    "\n",
    "ground_truth5 = \"MIT scientists developed battery tech for 50% more EV range, tested over 1,000 cycles, available by 2026\"\n",
    "\n",
    "hallucinations5 = [\n",
    "    \"Check for changed percentages or numbers\",\n",
    "    \"Check for invented researcher names or institutions\",\n",
    "    \"Check for fabricated quotes or statements\",\n",
    "    \"Check for added details not in original text\",\n",
    "    \"Check for changed dates or timelines\"\n",
    "]\n",
    "\n",
    "display_hallucination_comparison(\n",
    "    \"News Summarization - Battery Technology\",\n",
    "    \"Summarize the news article\",\n",
    "    ground_truth5,\n",
    "    gpt2_output5,\n",
    "    hallucinations5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb446e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background-color: #f0f0f0; padding: 20px; border-radius: 10px; margin: 10px 0; border: 2px solid #95a5a6;'>\n",
       "        <h3 style='color: #2c3e50;'>üß™ Test Case: Medical Summary - Arthritis Drug Trial</h3>\n",
       "        <div style='background-color: white; color: #2c3e50; padding: 15px; margin: 10px 0; border-left: 4px solid #3498db;'>\n",
       "            <strong style='font-size: 16px;'>üìù Prompt:</strong><br>\n",
       "            <span style='font-size: 16px; color: #2c3e50;'>Summarize the medical research</span>\n",
       "        </div>\n",
       "        <div style='background-color: #d4edda; color: #155724; padding: 15px; margin: 10px 0; border-left: 4px solid #28a745;'>\n",
       "            <strong style='font-size: 16px;'>‚úì Ground Truth (Actual Facts):</strong><br>\n",
       "            <span style='font-size: 16px; color: #155724;'>Clinical trial with 500 patients showed 35% symptom reduction, 12 months at Johns Hopkins, 8% had mild headaches</span>\n",
       "        </div>\n",
       "        <div style='background-color: #f8d7da; color: #721c24; padding: 15px; margin: 10px 0; border-left: 4px solid #dc3545; border: 2px solid #dc3545;'>\n",
       "            <strong style='font-size: 16px;'>‚ùå GPT-2 Output (Contains Hallucinations):</strong><br>\n",
       "            <span style='font-size: 16px; color: #721c24;'>A clinical trial involving 500 patients found that a new drug reduced \n",
       "symptoms of arthritis by 35% compared to placebo. The study was conducted over 12 months \n",
       "at Johns Hopkins Hospital. Side effects were minimal and included mild headaches in 8% of participants.\n",
       "\n",
       "Summary: The study found that a new drug that targets the same type of arthritis, which was found to increase the likelihood of a better-tolerated treatment, decreased symptoms of arthritis in patients who were treated with the drug.\n",
       "\n",
       "Researchers found that the new drug, the anti-inflammatory drug, was able to reduce the pain associated with pain, but only in patients who were treated with the drug.\n",
       "\n",
       "In addition, the study found that the drug's anti-inflammatory effect increased the pain of the joints and the pain of the joints that were treated with the new drug, so that the pain of the joints was reduced.\n",
       "\n",
       "\"This means that patients who are treated with the new drug can experience more pain relief and better quality of life,\" said Dr. Brian E. M. Vollman,</span>\n",
       "        </div>\n",
       "        <div style='background-color: #fff3cd; color: #856404; padding: 15px; margin: 10px 0; border-left: 4px solid #ffc107;'>\n",
       "            <strong style='font-size: 16px;'>üö® Identified Hallucinations:</strong><br>\n",
       "            <ul style='margin: 10px 0; font-size: 15px;'>\n",
       "    <li style='margin: 5px 0; color: #856404;'><strong>Check for incorrect patient numbers</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for changed effectiveness percentages</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for invented side effects</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for wrong hospital or location</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for fabricated medical claims</strong></li>\n",
       "            </ul>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "### üö® Critical Risk in Summarization\n",
       "When used for summarization, GPT-2:\n",
       "- **Adds information** that wasn't in the source\n",
       "- **Changes numerical values** (percentages, dates, quantities)\n",
       "- **Invents quotes** or attributions\n",
       "- **Alters key facts** while maintaining fluent language\n",
       "\n",
       "**This is especially dangerous in medical, legal, or financial contexts!**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 6: Medical Research Summarization\n",
    "medical_article = \"\"\"A clinical trial involving 500 patients found that a new drug reduced \n",
    "symptoms of arthritis by 35% compared to placebo. The study was conducted over 12 months \n",
    "at Johns Hopkins Hospital. Side effects were minimal and included mild headaches in 8% of participants.\"\"\"\n",
    "\n",
    "prompt6 = medical_article + \"\\n\\nSummary:\"\n",
    "\n",
    "gpt2_output6 = generate_gpt2_text(prompt6, max_length=220, temperature=0.7)\n",
    "\n",
    "ground_truth6 = \"Clinical trial with 500 patients showed 35% symptom reduction, 12 months at Johns Hopkins, 8% had mild headaches\"\n",
    "\n",
    "hallucinations6 = [\n",
    "    \"Check for incorrect patient numbers\",\n",
    "    \"Check for changed effectiveness percentages\",\n",
    "    \"Check for invented side effects\",\n",
    "    \"Check for wrong hospital or location\",\n",
    "    \"Check for fabricated medical claims\"\n",
    "]\n",
    "\n",
    "display_hallucination_comparison(\n",
    "    \"Medical Summary - Arthritis Drug Trial\",\n",
    "    \"Summarize the medical research\",\n",
    "    ground_truth6,\n",
    "    gpt2_output6,\n",
    "    hallucinations6\n",
    ")\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "### üö® Critical Risk in Summarization\n",
    "When used for summarization, GPT-2:\n",
    "- **Adds information** that wasn't in the source\n",
    "- **Changes numerical values** (percentages, dates, quantities)\n",
    "- **Invents quotes** or attributions\n",
    "- **Alters key facts** while maintaining fluent language\n",
    "\n",
    "**This is especially dangerous in medical, legal, or financial contexts!**\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7088c29",
   "metadata": {},
   "source": [
    "---\n",
    "# üéØ DEMONSTRATION 4: Question Answering Hallucination\n",
    "\n",
    "**Task:** Answer factual questions\n",
    "\n",
    "**Risk:** GPT-2 will provide confident but incorrect answers to straightforward questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0e145c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background-color: #f0f0f0; padding: 20px; border-radius: 10px; margin: 10px 0; border: 2px solid #95a5a6;'>\n",
       "        <h3 style='color: #2c3e50;'>üß™ Test Case: Question Answering - Number of Continents</h3>\n",
       "        <div style='background-color: white; color: #2c3e50; padding: 15px; margin: 10px 0; border-left: 4px solid #3498db;'>\n",
       "            <strong style='font-size: 16px;'>üìù Prompt:</strong><br>\n",
       "            <span style='font-size: 16px; color: #2c3e50;'>Q: How many continents are there on Earth?\n",
       "A:</span>\n",
       "        </div>\n",
       "        <div style='background-color: #d4edda; color: #155724; padding: 15px; margin: 10px 0; border-left: 4px solid #28a745;'>\n",
       "            <strong style='font-size: 16px;'>‚úì Ground Truth (Actual Facts):</strong><br>\n",
       "            <span style='font-size: 16px; color: #155724;'>There are 7 continents: Africa, Antarctica, Asia, Europe, North America, Australia (Oceania), and South America</span>\n",
       "        </div>\n",
       "        <div style='background-color: #f8d7da; color: #721c24; padding: 15px; margin: 10px 0; border-left: 4px solid #dc3545; border: 2px solid #dc3545;'>\n",
       "            <strong style='font-size: 16px;'>‚ùå GPT-2 Output (Contains Hallucinations):</strong><br>\n",
       "            <span style='font-size: 16px; color: #721c24;'>Q: How many continents are there on Earth?\n",
       "A: There are about 300 billion people in the world.\n",
       "Q: How many oceans are there on Earth?\n",
       "A: There are about 250 billion.\n",
       "Q: How many species of animals are there on Earth?\n",
       "A: There are about 50 billion.\n",
       "Q: How many species of reptiles are there on Earth?\n",
       "A</span>\n",
       "        </div>\n",
       "        <div style='background-color: #fff3cd; color: #856404; padding: 15px; margin: 10px 0; border-left: 4px solid #ffc107;'>\n",
       "            <strong style='font-size: 16px;'>üö® Identified Hallucinations:</strong><br>\n",
       "            <ul style='margin: 10px 0; font-size: 15px;'>\n",
       "    <li style='margin: 5px 0; color: #856404;'><strong>Check for incorrect number of continents</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for invented continent names</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for missing actual continents</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for nonsensical geographic claims</strong></li>\n",
       "            </ul>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 7: Simple Factual Question\n",
    "prompt7 = \"Q: How many continents are there on Earth?\\nA:\"\n",
    "\n",
    "gpt2_output7 = generate_gpt2_text(prompt7, max_length=80, temperature=0.7)\n",
    "\n",
    "ground_truth7 = \"There are 7 continents: Africa, Antarctica, Asia, Europe, North America, Australia (Oceania), and South America\"\n",
    "\n",
    "hallucinations7 = [\n",
    "    \"Check for incorrect number of continents\",\n",
    "    \"Check for invented continent names\",\n",
    "    \"Check for missing actual continents\",\n",
    "    \"Check for nonsensical geographic claims\"\n",
    "]\n",
    "\n",
    "display_hallucination_comparison(\n",
    "    \"Question Answering - Number of Continents\",\n",
    "    prompt7,\n",
    "    ground_truth7,\n",
    "    gpt2_output7,\n",
    "    hallucinations7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb09aae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background-color: #f0f0f0; padding: 20px; border-radius: 10px; margin: 10px 0; border: 2px solid #95a5a6;'>\n",
       "        <h3 style='color: #2c3e50;'>üß™ Test Case: Question Answering - Microsoft Founding</h3>\n",
       "        <div style='background-color: white; color: #2c3e50; padding: 15px; margin: 10px 0; border-left: 4px solid #3498db;'>\n",
       "            <strong style='font-size: 16px;'>üìù Prompt:</strong><br>\n",
       "            <span style='font-size: 16px; color: #2c3e50;'>Q: When was Microsoft founded?\n",
       "A:</span>\n",
       "        </div>\n",
       "        <div style='background-color: #d4edda; color: #155724; padding: 15px; margin: 10px 0; border-left: 4px solid #28a745;'>\n",
       "            <strong style='font-size: 16px;'>‚úì Ground Truth (Actual Facts):</strong><br>\n",
       "            <span style='font-size: 16px; color: #155724;'>Microsoft was founded on April 4, 1975, by Bill Gates and Paul Allen in Albuquerque, New Mexico</span>\n",
       "        </div>\n",
       "        <div style='background-color: #f8d7da; color: #721c24; padding: 15px; margin: 10px 0; border-left: 4px solid #dc3545; border: 2px solid #dc3545;'>\n",
       "            <strong style='font-size: 16px;'>‚ùå GPT-2 Output (Contains Hallucinations):</strong><br>\n",
       "            <span style='font-size: 16px; color: #721c24;'>Q: When was Microsoft founded?\n",
       "A: First, when we began. And then we had the Xbox. And then we had the Xbox 360. It was a bit of a mess. And then the Windows division was bought by Microsoft and it was a mess. And then we were all sold out in three months. So we had to be kind of a little bit more creative and try and keep things fresh.\n",
       "\n",
       "Q: I think</span>\n",
       "        </div>\n",
       "        <div style='background-color: #fff3cd; color: #856404; padding: 15px; margin: 10px 0; border-left: 4px solid #ffc107;'>\n",
       "            <strong style='font-size: 16px;'>üö® Identified Hallucinations:</strong><br>\n",
       "            <ul style='margin: 10px 0; font-size: 15px;'>\n",
       "    <li style='margin: 5px 0; color: #856404;'><strong>Check for incorrect founding year</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for wrong founders</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for incorrect location</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for invented company history details</strong></li>\n",
       "            </ul>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 8: Company Information\n",
    "prompt8 = \"Q: When was Microsoft founded?\\nA:\"\n",
    "\n",
    "gpt2_output8 = generate_gpt2_text(prompt8, max_length=90, temperature=0.7)\n",
    "\n",
    "ground_truth8 = \"Microsoft was founded on April 4, 1975, by Bill Gates and Paul Allen in Albuquerque, New Mexico\"\n",
    "\n",
    "hallucinations8 = [\n",
    "    \"Check for incorrect founding year\",\n",
    "    \"Check for wrong founders\",\n",
    "    \"Check for incorrect location\",\n",
    "    \"Check for invented company history details\"\n",
    "]\n",
    "\n",
    "display_hallucination_comparison(\n",
    "    \"Question Answering - Microsoft Founding\",\n",
    "    prompt8,\n",
    "    ground_truth8,\n",
    "    gpt2_output8,\n",
    "    hallucinations8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5e619a",
   "metadata": {},
   "source": [
    "---\n",
    "# üéØ DEMONSTRATION 5: Translation & Context Hallucination\n",
    "\n",
    "**Task:** Translate or explain concepts\n",
    "\n",
    "**Risk:** GPT-2 will add interpretations, context, or explanations that are fabricated or incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6a6cd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background-color: #f0f0f0; padding: 20px; border-radius: 10px; margin: 10px 0; border: 2px solid #95a5a6;'>\n",
       "        <h3 style='color: #2c3e50;'>üß™ Test Case: Technical Explanation - Quantum Computing</h3>\n",
       "        <div style='background-color: white; color: #2c3e50; padding: 15px; margin: 10px 0; border-left: 4px solid #3498db;'>\n",
       "            <strong style='font-size: 16px;'>üìù Prompt:</strong><br>\n",
       "            <span style='font-size: 16px; color: #2c3e50;'>Quantum computing is</span>\n",
       "        </div>\n",
       "        <div style='background-color: #d4edda; color: #155724; padding: 15px; margin: 10px 0; border-left: 4px solid #28a745;'>\n",
       "            <strong style='font-size: 16px;'>‚úì Ground Truth (Actual Facts):</strong><br>\n",
       "            <span style='font-size: 16px; color: #155724;'>Quantum computing is a type of computation that uses quantum-mechanical phenomena \n",
       "such as superposition and entanglement to perform operations on data</span>\n",
       "        </div>\n",
       "        <div style='background-color: #f8d7da; color: #721c24; padding: 15px; margin: 10px 0; border-left: 4px solid #dc3545; border: 2px solid #dc3545;'>\n",
       "            <strong style='font-size: 16px;'>‚ùå GPT-2 Output (Contains Hallucinations):</strong><br>\n",
       "            <span style='font-size: 16px; color: #721c24;'>Quantum computing is a quantum computer, it's very similar to a quantum computer but there are some differences. It's very powerful, it's very fast, it's very large, and it's also very hard to program. But this is a very powerful machine. It's a very powerful machine.\n",
       "\n",
       "Q: What's your next project?\n",
       "\n",
       "A: My next project is to use the quantum computer to solve the problem of the quantum computer. I think it's a very interesting idea.\n",
       "\n",
       "Q: What is the quantum computing system that you're working on?\n",
       "\n",
       "A: The quantum computer. That's right, it's the quantum computer. It's the quantum computer that's been built.\n",
       "\n",
       "Q:</span>\n",
       "        </div>\n",
       "        <div style='background-color: #fff3cd; color: #856404; padding: 15px; margin: 10px 0; border-left: 4px solid #ffc107;'>\n",
       "            <strong style='font-size: 16px;'>üö® Identified Hallucinations:</strong><br>\n",
       "            <ul style='margin: 10px 0; font-size: 15px;'>\n",
       "    <li style='margin: 5px 0; color: #856404;'><strong>Check for incorrect technical definitions</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for invented capabilities or applications</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for wrong scientific principles</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for fabricated examples or companies</strong></li>\n",
       "            </ul>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 9: Technical Term Explanation\n",
    "prompt9 = \"Quantum computing is\"\n",
    "\n",
    "gpt2_output9 = generate_gpt2_text(prompt9, max_length=150, temperature=0.7)\n",
    "\n",
    "ground_truth9 = \"\"\"Quantum computing is a type of computation that uses quantum-mechanical phenomena \n",
    "such as superposition and entanglement to perform operations on data\"\"\"\n",
    "\n",
    "hallucinations9 = [\n",
    "    \"Check for incorrect technical definitions\",\n",
    "    \"Check for invented capabilities or applications\",\n",
    "    \"Check for wrong scientific principles\",\n",
    "    \"Check for fabricated examples or companies\"\n",
    "]\n",
    "\n",
    "display_hallucination_comparison(\n",
    "    \"Technical Explanation - Quantum Computing\",\n",
    "    prompt9,\n",
    "    ground_truth9,\n",
    "    gpt2_output9,\n",
    "    hallucinations9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1a39014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background-color: #f0f0f0; padding: 20px; border-radius: 10px; margin: 10px 0; border: 2px solid #95a5a6;'>\n",
       "        <h3 style='color: #2c3e50;'>üß™ Test Case: Literary Fact - Hamlet Publication</h3>\n",
       "        <div style='background-color: white; color: #2c3e50; padding: 15px; margin: 10px 0; border-left: 4px solid #3498db;'>\n",
       "            <strong style='font-size: 16px;'>üìù Prompt:</strong><br>\n",
       "            <span style='font-size: 16px; color: #2c3e50;'>Shakespeare's Hamlet was written in</span>\n",
       "        </div>\n",
       "        <div style='background-color: #d4edda; color: #155724; padding: 15px; margin: 10px 0; border-left: 4px solid #28a745;'>\n",
       "            <strong style='font-size: 16px;'>‚úì Ground Truth (Actual Facts):</strong><br>\n",
       "            <span style='font-size: 16px; color: #155724;'>Shakespeare's Hamlet was written between 1599 and 1601, first published in 1603</span>\n",
       "        </div>\n",
       "        <div style='background-color: #f8d7da; color: #721c24; padding: 15px; margin: 10px 0; border-left: 4px solid #dc3545; border: 2px solid #dc3545;'>\n",
       "            <strong style='font-size: 16px;'>‚ùå GPT-2 Output (Contains Hallucinations):</strong><br>\n",
       "            <span style='font-size: 16px; color: #721c24;'>Shakespeare's Hamlet was written in 1494, as did the play of the same name by William Shakespeare. The following year, a large number of books were published, and the popularity of Shakespeare's plays increased by many years. In the end, however, no one thought that Hamlet was in any way a good play, and by the time the publication of Shakespeare's plays in the nineteenth century, the popularity of Shakespeare's plays was already declining.\n",
       "\n",
       "Hamlet was written in 1494, and the play of the same name by William Shakespeare. The following year, a large number</span>\n",
       "        </div>\n",
       "        <div style='background-color: #fff3cd; color: #856404; padding: 15px; margin: 10px 0; border-left: 4px solid #ffc107;'>\n",
       "            <strong style='font-size: 16px;'>üö® Identified Hallucinations:</strong><br>\n",
       "            <ul style='margin: 10px 0; font-size: 15px;'>\n",
       "    <li style='margin: 5px 0; color: #856404;'><strong>Check for incorrect dates</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for fabricated plot details</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for invented character names</strong></li><li style='margin: 5px 0; color: #856404;'><strong>Check for wrong historical context</strong></li>\n",
       "            </ul>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "### üí° Key Insight #2\n",
       "Across all categories - history, geography, news, medicine, and general knowledge - GPT-2 consistently:\n",
       "- **Generates fluent, convincing text**\n",
       "- **Lacks factual accuracy**\n",
       "- **Cannot verify its own outputs**\n",
       "- **Shows no uncertainty** even when wrong\n",
       "\n",
       "The model's confidence is NOT correlated with correctness!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 10: Literary Reference\n",
    "prompt10 = \"Shakespeare's Hamlet was written in\"\n",
    "\n",
    "gpt2_output10 = generate_gpt2_text(prompt10, max_length=120, temperature=0.7)\n",
    "\n",
    "ground_truth10 = \"Shakespeare's Hamlet was written between 1599 and 1601, first published in 1603\"\n",
    "\n",
    "hallucinations10 = [\n",
    "    \"Check for incorrect dates\",\n",
    "    \"Check for fabricated plot details\",\n",
    "    \"Check for invented character names\",\n",
    "    \"Check for wrong historical context\"\n",
    "]\n",
    "\n",
    "display_hallucination_comparison(\n",
    "    \"Literary Fact - Hamlet Publication\",\n",
    "    prompt10,\n",
    "    ground_truth10,\n",
    "    gpt2_output10,\n",
    "    hallucinations10\n",
    ")\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "### üí° Key Insight #2\n",
    "Across all categories - history, geography, news, medicine, and general knowledge - GPT-2 consistently:\n",
    "- **Generates fluent, convincing text**\n",
    "- **Lacks factual accuracy**\n",
    "- **Cannot verify its own outputs**\n",
    "- **Shows no uncertainty** even when wrong\n",
    "\n",
    "The model's confidence is NOT correlated with correctness!\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bde612",
   "metadata": {},
   "source": [
    "---\n",
    "# üìä Quantitative Analysis: Hallucination Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "513d5ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running consistency test (3 generations per prompt)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Prompt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Consistent",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Correct (out of 3)",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Hallucinations (out of 3)",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sample Output",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "cf12fde5-c5a2-4385-a799-1e0254abcb5b",
       "rows": [
        [
         "0",
         "Geography",
         "The capital of France is",
         "No",
         "0",
         "3",
         "The capital of France is now one of the most important cities in Europe. Its wealth and its culture ..."
        ],
        [
         "1",
         "History",
         "World War I started in",
         "No",
         "0",
         "3",
         "World War I started in 1919, and the first World War II began in 1940.\n\nAnd the United States has ha..."
        ],
        [
         "2",
         "Science",
         "The speed of light is",
         "No",
         "0",
         "3",
         "The speed of light is one of the most fundamental factors of human evolution. By using light to see ..."
        ],
        [
         "3",
         "Technology",
         "The first iPhone was released in",
         "No",
         "1",
         "2",
         "The first iPhone was released in 2007. It was released in late 2009, and it has been the most popula..."
        ],
        [
         "4",
         "Geography",
         "The largest ocean on Earth is",
         "No",
         "0",
         "3",
         "The largest ocean on Earth is about 1,400 miles (1,500 kilometers) deep. That's about the width of t..."
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Consistent</th>\n",
       "      <th>Correct (out of 3)</th>\n",
       "      <th>Hallucinations (out of 3)</th>\n",
       "      <th>Sample Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geography</td>\n",
       "      <td>The capital of France is</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>The capital of France is now one of the most i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>History</td>\n",
       "      <td>World War I started in</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>World War I started in 1919, and the first Wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Science</td>\n",
       "      <td>The speed of light is</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>The speed of light is one of the most fundamen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technology</td>\n",
       "      <td>The first iPhone was released in</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>The first iPhone was released in 2007. It was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geography</td>\n",
       "      <td>The largest ocean on Earth is</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>The largest ocean on Earth is about 1,400 mile...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                            Prompt Consistent  \\\n",
       "0   Geography          The capital of France is         No   \n",
       "1     History            World War I started in         No   \n",
       "2     Science             The speed of light is         No   \n",
       "3  Technology  The first iPhone was released in         No   \n",
       "4   Geography     The largest ocean on Earth is         No   \n",
       "\n",
       "   Correct (out of 3)  Hallucinations (out of 3)  \\\n",
       "0                   0                          3   \n",
       "1                   0                          3   \n",
       "2                   0                          3   \n",
       "3                   1                          2   \n",
       "4                   0                          3   \n",
       "\n",
       "                                       Sample Output  \n",
       "0  The capital of France is now one of the most i...  \n",
       "1  World War I started in 1919, and the first Wor...  \n",
       "2  The speed of light is one of the most fundamen...  \n",
       "3  The first iPhone was released in 2007. It was ...  \n",
       "4  The largest ocean on Earth is about 1,400 mile...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "### üìà Summary Statistics:\n",
       "- **Consistency Rate:** 0.0% (how often 3 generations are identical)\n",
       "- **Accuracy Rate:** 6.7% (how often outputs contain correct answer)\n",
       "- **Hallucination Rate:** 93.3% (how often outputs contain factual errors)\n",
       "\n",
       "**Observation:** Low consistency shows GPT-2 generates different outputs for the same prompt, \n",
       "low accuracy proves unreliability, and high hallucination rate demonstrates systematic failure at factual tasks.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run multiple generations to measure consistency\n",
    "test_prompts = [\n",
    "    {\"prompt\": \"The capital of France is\", \"correct\": \"Paris\", \"category\": \"Geography\"},\n",
    "    {\"prompt\": \"World War I started in\", \"correct\": \"1914\", \"category\": \"History\"},\n",
    "    {\"prompt\": \"The speed of light is\", \"correct\": \"299,792,458 m/s\", \"category\": \"Science\"},\n",
    "    {\"prompt\": \"The first iPhone was released in\", \"correct\": \"2007\", \"category\": \"Technology\"},\n",
    "    {\"prompt\": \"The largest ocean on Earth is\", \"correct\": \"Pacific Ocean\", \"category\": \"Geography\"},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Running consistency test (3 generations per prompt)...\\n\")\n",
    "\n",
    "for test in test_prompts:\n",
    "    generations = []\n",
    "    for i in range(3):\n",
    "        output = generate_gpt2_text(test['prompt'], max_length=50, temperature=0.7)\n",
    "        generations.append(output)\n",
    "    \n",
    "    # Check if all generations are identical\n",
    "    consistent = len(set(generations)) == 1\n",
    "    \n",
    "    # Check if any contain the correct answer\n",
    "    correct_count = sum(1 for gen in generations if test['correct'].lower() in gen.lower())\n",
    "    \n",
    "    # Check for hallucinations (outputs that don't contain correct answer)\n",
    "    hallucination_count = 3 - correct_count\n",
    "    \n",
    "    results.append({\n",
    "        'Category': test['category'],\n",
    "        'Prompt': test['prompt'],\n",
    "        'Consistent': 'Yes' if consistent else 'No',\n",
    "        'Correct (out of 3)': correct_count,\n",
    "        'Hallucinations (out of 3)': hallucination_count,\n",
    "        'Sample Output': generations[0][:100] + \"...\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "display(df)\n",
    "\n",
    "# Summary statistics\n",
    "consistency_rate = (df['Consistent'] == 'Yes').sum() / len(df) * 100\n",
    "avg_correctness = df['Correct (out of 3)'].mean() / 3 * 100\n",
    "hallucination_rate = 100 - avg_correctness  # Percentage of outputs with factual errors\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "### üìà Summary Statistics:\n",
    "- **Consistency Rate:** {consistency_rate:.1f}% (how often 3 generations are identical)\n",
    "- **Accuracy Rate:** {avg_correctness:.1f}% (how often outputs contain correct answer)\n",
    "- **Hallucination Rate:** {hallucination_rate:.1f}% (how often outputs contain factual errors)\n",
    "\n",
    "**Observation:** Low consistency shows GPT-2 generates different outputs for the same prompt, \n",
    "low accuracy proves unreliability, and high hallucination rate demonstrates systematic failure at factual tasks.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c0fbc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå GPT-2 shows poor factual accuracy across all categories!\n"
     ]
    }
   ],
   "source": [
    "# Visualization: Hallucination by Category\n",
    "category_data = df.groupby('Category')['Correct (out of 3)'].mean() / 3 * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = category_data.plot(kind='bar', ax=ax, color='#e74c3c', edgecolor='black', linewidth=1.2)\n",
    "ax.set_xlabel('Category', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('GPT-2 Factual Accuracy by Category', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.axhline(y=50, color='red', linestyle='--', label='50% (Random Guess)')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.legend()\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(category_data.values):\n",
    "    ax.text(i, v + 2, f'{v:.1f}%', ha='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚ùå GPT-2 shows poor factual accuracy across all categories!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58e69a6",
   "metadata": {},
   "source": [
    "---\n",
    "# üéì Key Takeaways\n",
    "\n",
    "## What We Proved:\n",
    "1. **GPT-2 frequently hallucinates** - generating plausible but factually incorrect information\n",
    "2. **Hallucinations occur across all domains** - history, geography, science, news, and general knowledge\n",
    "3. **The model shows no uncertainty** - it generates incorrect information with the same confidence as correct information\n",
    "4. **Inconsistent outputs** - the same prompt produces different (often wrong) results\n",
    "\n",
    "## Why This Happens:\n",
    "- **GPT-2 is a statistical model** - it predicts likely word sequences, not facts\n",
    "- **No fact-checking mechanism** - the model cannot verify information against reliable sources\n",
    "- **No knowledge representation** - it doesn't \"know\" facts, it pattern-matches from training data\n",
    "- **No uncertainty awareness** - it can't say \"I don't know\"\n",
    "\n",
    "## Real-World Implications:\n",
    "- ‚ùå **Unreliable for summarization** - adds or changes critical details\n",
    "- ‚ùå **Dangerous for Q&A systems** - provides confident but wrong answers\n",
    "- ‚ùå **Risky for content generation** - spreads misinformation\n",
    "- ‚ùå **Unsuitable for fact-based applications** - medical, legal, financial, news\n",
    "\n",
    "## What's Needed:\n",
    "1. **Fact verification systems** - external knowledge bases and fact-checking\n",
    "2. **Uncertainty quantification** - models should indicate confidence levels\n",
    "3. **Retrieval-augmented generation** - combine language models with search\n",
    "4. **Human oversight** - critical review of AI-generated content\n",
    "5. **User education** - understanding model limitations\n",
    "\n",
    "---\n",
    "\n",
    "## üö® Final Warning\n",
    "\n",
    "> *\"The danger of AI hallucination is not just that it generates false information, but that it does so with such fluency and confidence that humans may trust it without verification. This makes language models particularly risky for applications where factual accuracy matters.\"*\n",
    "\n",
    "**GPT-2 is a powerful text generator - but it is NOT a reliable source of factual information.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f2b76",
   "metadata": {},
   "source": [
    "---\n",
    "# üî¨ Interactive Testing Area\n",
    "\n",
    "Use this cell to test your own examples during the live demo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ba6c186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='background-color: #f0f0f0; padding: 20px; border-radius: 10px; margin: 10px 0; border: 2px solid #95a5a6;'>\n",
       "        <h3 style='color: #2c3e50;'>üß™ Test Case: Custom Test</h3>\n",
       "        <div style='background-color: white; color: #2c3e50; padding: 15px; margin: 10px 0; border-left: 4px solid #3498db;'>\n",
       "            <strong style='font-size: 16px;'>üìù Prompt:</strong><br>\n",
       "            <span style='font-size: 16px; color: #2c3e50;'>YOUR PROMPT HERE</span>\n",
       "        </div>\n",
       "        <div style='background-color: #d4edda; color: #155724; padding: 15px; margin: 10px 0; border-left: 4px solid #28a745;'>\n",
       "            <strong style='font-size: 16px;'>‚úì Ground Truth (Actual Facts):</strong><br>\n",
       "            <span style='font-size: 16px; color: #155724;'>THE ACTUAL FACTS HERE</span>\n",
       "        </div>\n",
       "        <div style='background-color: #f8d7da; color: #721c24; padding: 15px; margin: 10px 0; border-left: 4px solid #dc3545; border: 2px solid #dc3545;'>\n",
       "            <strong style='font-size: 16px;'>‚ùå GPT-2 Output (Contains Hallucinations):</strong><br>\n",
       "            <span style='font-size: 16px; color: #721c24;'>YOUR PROMPT HERE: http://www.youtube.com/watch?v=4YQF0T4-RpA\n",
       "\n",
       "FINAL THOUGHTS:\n",
       "\n",
       "- Some of my favorite characters are not in this video.\n",
       "\n",
       "- The sound effects are awesome.\n",
       "\n",
       "- I really like the way the music is done.\n",
       "\n",
       "- I would love to see more of this, but I'm not sure I'll get to that point yet.\n",
       "\n",
       "- I am not 100% sure I will be able to read the video, but I think it will be worth the wait.\n",
       "\n",
       "- I have a feeling that this is going to be a great video for all ages and levels of play</span>\n",
       "        </div>\n",
       "        <div style='background-color: #fff3cd; color: #856404; padding: 15px; margin: 10px 0; border-left: 4px solid #ffc107;'>\n",
       "            <strong style='font-size: 16px;'>üö® Identified Hallucinations:</strong><br>\n",
       "            <ul style='margin: 10px 0; font-size: 15px;'>\n",
       "    <li style='margin: 5px 0; color: #856404;'><strong>Check the output for factual accuracy</strong></li>\n",
       "            </ul>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try your own test case!\n",
    "custom_prompt = \"YOUR PROMPT HERE\"\n",
    "custom_ground_truth = \"THE ACTUAL FACTS HERE\"\n",
    "\n",
    "custom_output = generate_gpt2_text(custom_prompt, max_length=150, temperature=0.7)\n",
    "\n",
    "display_hallucination_comparison(\n",
    "    \"Custom Test\",\n",
    "    custom_prompt,\n",
    "    custom_ground_truth,\n",
    "    custom_output,\n",
    "    [\"Check the output for factual accuracy\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
